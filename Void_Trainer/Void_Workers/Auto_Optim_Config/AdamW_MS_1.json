{
    "optimizer_name": "AdamW",
    "learning_rate_scheduler": "Multistep",
    "milestone": [4, 8, 12],
    "gamma": 0.5,
    "learning_rate": 2e-4,
    "weight_decay": 0.05,
    "gradient_clip": 1.0
}